{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa641eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dspy\n",
      "  Downloading dspy-3.0.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting backoff>=2.2 (from dspy)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: joblib~=1.3 in /home/codespace/.local/lib/python3.12/site-packages (from dspy) (1.5.0)\n",
      "Requirement already satisfied: openai>=0.28.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from dspy) (1.100.2)\n",
      "Collecting regex>=2023.10.3 (from dspy)\n",
      "  Downloading regex-2025.7.34-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Collecting ujson>=5.8.0 (from dspy)\n",
      "  Downloading ujson-5.11.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from dspy) (4.66.4)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/codespace/.local/lib/python3.12/site-packages (from dspy) (2.32.3)\n",
      "Collecting optuna>=3.4.0 (from dspy)\n",
      "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: pydantic>=2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from dspy) (2.11.7)\n",
      "Collecting magicattr>=0.1.6 (from dspy)\n",
      "  Downloading magicattr-0.1.6-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting litellm>=1.64.0 (from dspy)\n",
      "  Downloading litellm-1.75.8-py3-none-any.whl.metadata (41 kB)\n",
      "Collecting diskcache>=5.6.0 (from dspy)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting json-repair>=0.30.0 (from dspy)\n",
      "  Downloading json_repair-0.50.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting tenacity>=8.2.3 (from dspy)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: anyio in /home/codespace/.local/lib/python3.12/site-packages (from dspy) (4.9.0)\n",
      "Collecting asyncer==0.0.8 (from dspy)\n",
      "  Downloading asyncer-0.0.8-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting cachetools>=5.5.0 (from dspy)\n",
      "  Downloading cachetools-6.1.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting cloudpickle>=3.0.0 (from dspy)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting rich>=13.7.1 (from dspy)\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/codespace/.local/lib/python3.12/site-packages (from dspy) (2.2.5)\n",
      "Collecting xxhash>=3.5.0 (from dspy)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting gepa==0.0.4 (from gepa[dspy]==0.0.4->dspy)\n",
      "  Downloading gepa-0.0.4-py3-none-any.whl.metadata (10 kB)\n"
     ]
    }
   ],
   "source": [
    "#!pip install openai\n",
    "#!pip install dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46299d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "opeanai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c9d9fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add an env secret:\n",
    "# Browse to the code repo > settings > Secrets and variables > Codespaces\n",
    "# https://github.com/YOURREPONAME/settings/secrets/codespaces\n",
    "# Click: Add new repository key\n",
    "# Create key, don't use quotes on value\n",
    "\n",
    "opeanai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_model = 'gpt-4.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9a26fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adf43871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=opeanai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ba8f612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo\n",
      "gpt-4-turbo\n",
      "gpt-4o-mini\n",
      "gpt-4.1\n"
     ]
    }
   ],
   "source": [
    "# List available OpenAI models using the client\n",
    "# To modify what models you can call\n",
    "# Browse: https://platform.openai.com/settings/\n",
    "# Click on SECOND \"Limits\" menu option (there are two)\n",
    "# On the \"Project limits\" page look at \"Allowed models\" section\n",
    "\n",
    "models = client.models.list()\n",
    "\n",
    "for model in models.data:\n",
    "    print(model.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4288d03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "def md(text: str) -> None:\n",
    "    display(Markdown(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd74e841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The Los Angeles Dodgers won the World Series in 2020. They defeated the Tampa Bay Rays, winning the series 4 games to 2. It was the Dodgers' first World Series title since 1988."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=openai_model,\n",
    "    #model=\"gpt-5-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello, who won the world series in 2020?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "md(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20685ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Model**: gpt-3.5-turbo"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Dedicated volunteers clear debris."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Model**: gpt-4-turbo"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Volunteers cleared debris during storm."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Model**: gpt-4o-mini"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Volunteers cleared debris in storms."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Model**: gpt-4.1"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Volunteers cleared debris despite storm."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def call_model(model_name: str, prompt: str) -> None:\n",
    "    \"\"\"\n",
    "    Call the OpenAI model with a given prompt.\n",
    "    \n",
    "    \"\"\"\n",
    "    lm = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return lm\n",
    "\n",
    "for m in models.data:\n",
    "    md('**Model**: ' + m.id)\n",
    "    if model.id == 'gpt-4-turbo':\n",
    "        md('Skipping this model')\n",
    "        continue\n",
    "\n",
    "    #md(call_model(m.id, \"What is the capital of France in 500BC?\").choices[0].message.content)\n",
    "    md(call_model(m.id, \"\"\"\n",
    "                  Summarize this sentence to 5 words or less:  \n",
    "                  Despite heavy rain and strong winds, the dedicated volunteers continued clearing debris \n",
    "                  from the flooded streets to help stranded residents reach safety.\n",
    "                  \"\"\").choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b8940ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2eebd6b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dspy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdspy\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'dspy'"
     ]
    }
   ],
   "source": [
    "import dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f507fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To make API calls to models **other than `gpt-4.0`/`gpt-4.1`** (for example, `gpt-3.5-turbo`, `gpt-4-turbo`, `dall-e-3`, `whisper-1`, etc.) using the **OpenAI Python library**, you simply need to specify the desired model in your API call. **No special access is required for most models** (except for some, like `gpt-4` or `dall-e-3`, which may require you to have billing enabled or be in a waitlist).\n",
       "\n",
       "### 1. Install the OpenAI Python library\n",
       "\n",
       "```bash\n",
       "pip install openai\n",
       "```\n",
       "\n",
       "### 2. Set your API key\n",
       "\n",
       "```python\n",
       "import openai\n",
       "\n",
       "openai.api_key = \"sk-...\"  # Replace with your API key\n",
       "```\n",
       "\n",
       "### 3. Specify the model in your API call\n",
       "\n",
       "#### For Chat Models (e.g., `gpt-3.5-turbo`, `gpt-4-turbo`):\n",
       "\n",
       "```python\n",
       "response = openai.ChatCompletion.create(\n",
       "    model=\"gpt-3.5-turbo\",  # or \"gpt-4-turbo\", \"gpt-4o\", etc.\n",
       "    messages=[\n",
       "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
       "        {\"role\": \"user\", \"content\": \"Hello!\"},\n",
       "    ]\n",
       ")\n",
       "print(response.choices[0].message.content)\n",
       "```\n",
       "\n",
       "#### For Text Completion Models (e.g., `text-davinci-003`):\n",
       "\n",
       "```python\n",
       "response = openai.Completion.create(\n",
       "    model=\"text-davinci-003\",\n",
       "    prompt=\"Once upon a time,\",\n",
       "    max_tokens=50\n",
       ")\n",
       "print(response.choices[0].text)\n",
       "```\n",
       "\n",
       "#### For Image Generation (e.g., `dall-e-3`):\n",
       "\n",
       "```python\n",
       "response = openai.Image.create(\n",
       "    model=\"dall-e-3\",\n",
       "    prompt=\"A futuristic cityscape at sunset\",\n",
       "    n=1,\n",
       "    size=\"1024x1024\"\n",
       ")\n",
       "print(response['data'][0]['url'])\n",
       "```\n",
       "\n",
       "#### For Audio Transcription (e.g., `whisper-1`):\n",
       "\n",
       "```python\n",
       "audio_file = open(\"audio.mp3\", \"rb\")\n",
       "transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
       "print(transcript[\"text\"])\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "## **How to know which models you have access to?**\n",
       "\n",
       "You can list available models with:\n",
       "\n",
       "```python\n",
       "models = openai.Model.list()\n",
       "for model in models['data']:\n",
       "    print(model['id'])\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "## **Notes:**\n",
       "\n",
       "- **Some models (like `gpt-4`, `dall-e-3`) may require you to have a paid account or be on a waitlist.** If you get an error like `You do not have access to this model`, check your account status or upgrade.\n",
       "- **Always check the [OpenAI API documentation](https://platform.openai.com/docs/models/overview)** for the latest model names and access requirements.\n",
       "- **The model name is specified in the `model` parameter** of your API call.\n",
       "\n",
       "---\n",
       "\n",
       "**In summary:**  \n",
       "You do **not** need to do anything special to access other models, just specify the model name in your API call, as long as your account has access to it. If you get an access error, check your account or billing status."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dspy\n",
    "\n",
    "# Create a DSPY language model object using the OpenAI client\n",
    "lm = dspy.LM(\n",
    "    model=\"gpt-4.1\",         # or another available model\n",
    "    api_key=client.api_key,        # reuse the api_key from your OpenAI client\n",
    "    provider=\"openai\"              # specify the provider\n",
    ")\n",
    "\n",
    "# Example prompt\n",
    "prompt = \"What is the capital of France in 500BC?\"\n",
    "prompt = \"How do I get access to make api calls to models other than gp-4.1 on openai via python OpenAI?\"\n",
    "\n",
    "# Call the language model\n",
    "response = lm(prompt)\n",
    "\n",
    "md(response[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

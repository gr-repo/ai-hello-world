{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa641eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai\n",
    "#!pip install dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46299d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "opeanai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c9d9fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "opeanai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_model = 'gpt-4.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9a26fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adf43871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=opeanai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ba8f612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo\n",
      "gpt-4-turbo\n",
      "gpt-4o-mini\n",
      "gpt-4.1\n"
     ]
    }
   ],
   "source": [
    "# List available OpenAI models using the client\n",
    "# To modify what models you can call\n",
    "# Browse: https://platform.openai.com/settings/\n",
    "# Click on SECOND \"Limits\" menu option (there are two)\n",
    "# On the \"Project limits\" page look at \"Allowed models\" section\n",
    "\n",
    "models = client.models.list()\n",
    "\n",
    "for model in models.data:\n",
    "    print(model.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4288d03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "def md(text: str) -> None:\n",
    "    display(Markdown(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd74e841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The Los Angeles Dodgers won the World Series in 2020. They defeated the Tampa Bay Rays, clinching the championship in six games. This was the Dodgers' first World Series title since 1988."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=openai_model,\n",
    "    #model=\"gpt-5-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello, who won the world series in 2020?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "md(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20685ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Model**: gpt-3.5-turbo"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Volunteers cleared debris in storm."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Model**: gpt-4-turbo"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Volunteers cleared debris despite weather."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Model**: gpt-4o-mini"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Volunteers cleared debris in storms."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Model**: gpt-4.1"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Volunteers cleared debris amid storm."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def call_model(model_name: str, prompt: str) -> None:\n",
    "    \"\"\"\n",
    "    Call the OpenAI model with a given prompt.\n",
    "    \n",
    "    \"\"\"\n",
    "    lm = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return lm\n",
    "\n",
    "for m in models.data:\n",
    "    md('**Model**: ' + m.id)\n",
    "    if model.id == 'gpt-4-turbo':\n",
    "        md('Skipping this model')\n",
    "        continue\n",
    "\n",
    "    #md(call_model(m.id, \"What is the capital of France in 500BC?\").choices[0].message.content)\n",
    "    md(call_model(m.id, \"\"\"\n",
    "                  Summarize this sentence to 5 words or less:  \n",
    "                  Despite heavy rain and strong winds, the dedicated volunteers continued clearing debris \n",
    "                  from the flooded streets to help stranded residents reach safety.\n",
    "                  \"\"\").choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b8940ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2eebd6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0f507fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To make API calls to models **other than `gpt-4.0` or `gpt-4.1`** (for example, `gpt-3.5-turbo`, `gpt-4-turbo`, `dall-e-3`, `whisper-1`, etc.) using the **OpenAI Python library**, you simply need to specify the desired model in your API call. **No special access is required** for most models, except for some (like `gpt-4` or `dall-e-3`) which may require you to have a paid account or be in a waitlist.\n",
       "\n",
       "### 1. **Install the OpenAI Python Library**\n",
       "```bash\n",
       "pip install openai\n",
       "```\n",
       "\n",
       "### 2. **Set Your API Key**\n",
       "```python\n",
       "import openai\n",
       "\n",
       "openai.api_key = \"sk-...\"  # Replace with your actual API key\n",
       "```\n",
       "\n",
       "### 3. **Specify the Model in Your API Call**\n",
       "\n",
       "#### **For Chat Models (e.g., gpt-3.5-turbo, gpt-4-turbo)**\n",
       "```python\n",
       "response = openai.ChatCompletion.create(\n",
       "    model=\"gpt-3.5-turbo\",  # or \"gpt-4-turbo\", \"gpt-4-1106-preview\", etc.\n",
       "    messages=[\n",
       "        {\"role\": \"user\", \"content\": \"Hello, who are you?\"}\n",
       "    ]\n",
       ")\n",
       "print(response.choices[0].message.content)\n",
       "```\n",
       "\n",
       "#### **For Text Completion Models (e.g., text-davinci-003)**\n",
       "```python\n",
       "response = openai.Completion.create(\n",
       "    model=\"text-davinci-003\",\n",
       "    prompt=\"Once upon a time,\",\n",
       "    max_tokens=50\n",
       ")\n",
       "print(response.choices[0].text)\n",
       "```\n",
       "\n",
       "#### **For Image Generation (DALLÂ·E)**\n",
       "```python\n",
       "response = openai.Image.create(\n",
       "    model=\"dall-e-3\",  # or \"dall-e-2\"\n",
       "    prompt=\"A futuristic cityscape at sunset\",\n",
       "    n=1,\n",
       "    size=\"1024x1024\"\n",
       ")\n",
       "print(response['data'][0]['url'])\n",
       "```\n",
       "\n",
       "#### **For Audio Transcription (Whisper)**\n",
       "```python\n",
       "audio_file = open(\"audio.mp3\", \"rb\")\n",
       "transcript = openai.Audio.transcribe(\n",
       "    model=\"whisper-1\",\n",
       "    file=audio_file\n",
       ")\n",
       "print(transcript['text'])\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "## **How to Know Which Models You Have Access To?**\n",
       "\n",
       "You can list available models with:\n",
       "```python\n",
       "models = openai.Model.list()\n",
       "for m in models['data']:\n",
       "    print(m['id'])\n",
       "```\n",
       "> **Note:** Some models may not appear if you don't have access. If you try to use a model you don't have access to, you'll get an error.\n",
       "\n",
       "---\n",
       "\n",
       "## **Summary Table**\n",
       "\n",
       "| Model Name         | Usage Example (Python)         | Access Requirements         |\n",
       "|--------------------|-------------------------------|----------------------------|\n",
       "| gpt-3.5-turbo      | `model=\"gpt-3.5-turbo\"`       | Free/Paid                  |\n",
       "| gpt-4-turbo        | `model=\"gpt-4-turbo\"`         | Paid, some waitlist        |\n",
       "| gpt-4-1106-preview | `model=\"gpt-4-1106-preview\"`  | Paid, some waitlist        |\n",
       "| text-davinci-003   | `model=\"text-davinci-003\"`    | Free/Paid                  |\n",
       "| dall-e-3           | `model=\"dall-e-3\"`            | Paid, some waitlist        |\n",
       "| whisper-1          | `model=\"whisper-1\"`           | Free/Paid                  |\n",
       "\n",
       "---\n",
       "\n",
       "## **Troubleshooting**\n",
       "\n",
       "- **If you get a \"model not found\" or \"you do not have access\" error:**  \n",
       "  - Make sure your account has access (check [OpenAI platform](https://platform.openai.com/)).\n",
       "  - Some models require a paid account or are in limited beta.\n",
       "  - Check your API key and organization.\n",
       "\n",
       "---\n",
       "\n",
       "## **References**\n",
       "- [OpenAI API Documentation](https://platform.openai.com/docs/)\n",
       "- [OpenAI Model List](https://platform.openai.com/docs/models/overview)\n",
       "\n",
       "---\n",
       "\n",
       "**In summary:**  \n",
       "Just specify the model you want in the `model` parameter. No special code is needed for different models, but you must have access to the model on your OpenAI account. If you get an error, check your account's access and billing status."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dspy\n",
    "\n",
    "# Create a DSPY language model object using the OpenAI client\n",
    "lm = dspy.LM(\n",
    "    model=\"gpt-4.1\",         # or another available model\n",
    "    api_key=client.api_key,        # reuse the api_key from your OpenAI client\n",
    "    provider=\"openai\"              # specify the provider\n",
    ")\n",
    "\n",
    "# Example prompt\n",
    "prompt = \"What is the capital of France in 500BC?\"\n",
    "prompt = \"How do I get access to make api calls to models other than gp-4.1 on openai via python OpenAI?\"\n",
    "\n",
    "# Call the language model\n",
    "response = lm(prompt)\n",
    "\n",
    "md(response[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

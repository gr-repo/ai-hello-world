{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa641eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai\n",
    "#!pip install dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46299d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "opeanai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_model = 'gpt-4.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf43871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=opeanai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba8f612",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = client.models.list()\n",
    "\n",
    "# List available models you can call. See README.me for more details on setting others up.\n",
    "for model in models.data:\n",
    "    print(model.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4288d03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "def md(text: str) -> None:\n",
    "    display(Markdown(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd74e841",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=openai_model,\n",
    "    #model=\"gpt-5-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello, who won the world series in 2020?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "md(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20685ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model(model_name: str, prompt: str) -> None:\n",
    "    \"\"\"\n",
    "    Call the OpenAI model with a given prompt.\n",
    "    \n",
    "    \"\"\"\n",
    "    lm = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return lm\n",
    "\n",
    "for m in models.data:\n",
    "    md('**Model**: ' + m.id)\n",
    "    if model.id == 'gpt-4-turbo':\n",
    "        md('Skipping this model')\n",
    "        continue\n",
    "\n",
    "    #md(call_model(m.id, \"What is the capital of France in 500BC?\").choices[0].message.content)\n",
    "    md(call_model(m.id, \"\"\"\n",
    "                  Summarize this sentence to 5 words or less:  \n",
    "                  Despite heavy rain and strong winds, the dedicated volunteers continued clearing debris \n",
    "                  from the flooded streets to help stranded residents reach safety.\n",
    "                  \"\"\").choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

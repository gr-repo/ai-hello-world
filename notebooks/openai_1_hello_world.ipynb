{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46299d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "opeanai_api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c9d9fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add an env secret:\n",
    "# Browse to the code repo > settings > Secrets and variables > Codespaces\n",
    "# https://github.com/YOURREPONAME/settings/secrets/codespaces\n",
    "# Click: Add new repository key\n",
    "# Create key, don't use quotes on value\n",
    "\n",
    "opeanai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_model = 'gpt-4.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9a26fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.100.2-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Requirement already satisfied: sniffio in /home/codespace/.local/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/codespace/.local/lib/python3.12/site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading openai-1.100.2-py3-none-any.whl (787 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m787.8/787.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-inspection, pydantic-core, jiter, distro, annotated-types, pydantic, openai\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7/7\u001b[0m [openai]2m6/7\u001b[0m [openai]c]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 distro-1.9.0 jiter-0.10.0 openai-1.100.2 pydantic-2.11.7 pydantic-core-2.33.2 typing-inspection-0.4.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adf43871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=opeanai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ba8f612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo\n",
      "gpt-4-turbo\n",
      "gpt-4o-mini\n",
      "gpt-4.1\n"
     ]
    }
   ],
   "source": [
    "# List available OpenAI models using the client\n",
    "# To modify what models you can call\n",
    "# Browse: https://platform.openai.com/settings/\n",
    "# Click on SECOND \"Limits\" menu option (there are two)\n",
    "# On the \"Project limits\" page look at \"Allowed models\" section\n",
    "\n",
    "models = client.models.list()\n",
    "\n",
    "for model in models.data:\n",
    "    print(model.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4288d03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "def md(text: str) -> None:\n",
    "    display(Markdown(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd74e841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The **Los Angeles Dodgers** won the World Series in 2020. They defeated the Tampa Bay Rays in six games to capture their first championship since 1988."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=openai_model,\n",
    "    #model=\"gpt-5-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello, who won the world series in 2020?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "md(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20685ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Model**: gpt-3.5-turbo"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Volunteers cleared debris in storm."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Model**: gpt-4-turbo"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Volunteers cleared debris in storm."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Model**: gpt-4o-mini"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Volunteers cleared debris in storms."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Model**: gpt-4.1"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Volunteers cleared debris despite storm."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def call_model(model_name: str, prompt: str) -> None:\n",
    "    \"\"\"\n",
    "    Call the OpenAI model with a given prompt.\n",
    "    \n",
    "    \"\"\"\n",
    "    lm = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return lm\n",
    "\n",
    "for m in models.data:\n",
    "    md('**Model**: ' + m.id)\n",
    "    if model.id == 'gpt-4-turbo':\n",
    "        md('Skipping this model')\n",
    "        continue\n",
    "\n",
    "    #md(call_model(m.id, \"What is the capital of France in 500BC?\").choices[0].message.content)\n",
    "    md(call_model(m.id, \"\"\"\n",
    "                  Summarize this sentence to 5 words or less:  \n",
    "                  Despite heavy rain and strong winds, the dedicated volunteers continued clearing debris \n",
    "                  from the flooded streets to help stranded residents reach safety.\n",
    "                  \"\"\").choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b8940ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dspy\n",
      "  Downloading dspy-3.0.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting backoff>=2.2 (from dspy)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: joblib~=1.3 in /home/codespace/.local/lib/python3.12/site-packages (from dspy) (1.5.0)\n",
      "Requirement already satisfied: openai>=0.28.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from dspy) (1.100.2)\n",
      "Collecting regex>=2023.10.3 (from dspy)\n",
      "  Downloading regex-2025.7.34-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Collecting ujson>=5.8.0 (from dspy)\n",
      "  Downloading ujson-5.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from dspy) (4.66.4)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/codespace/.local/lib/python3.12/site-packages (from dspy) (2.32.3)\n",
      "Collecting optuna>=3.4.0 (from dspy)\n",
      "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: pydantic>=2.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from dspy) (2.11.7)\n",
      "Collecting magicattr>=0.1.6 (from dspy)\n",
      "  Downloading magicattr-0.1.6-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting litellm>=1.64.0 (from dspy)\n",
      "  Downloading litellm-1.75.8-py3-none-any.whl.metadata (41 kB)\n",
      "Collecting diskcache>=5.6.0 (from dspy)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting json-repair>=0.30.0 (from dspy)\n",
      "  Downloading json_repair-0.49.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting tenacity>=8.2.3 (from dspy)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: anyio in /home/codespace/.local/lib/python3.12/site-packages (from dspy) (4.9.0)\n",
      "Collecting asyncer==0.0.8 (from dspy)\n",
      "  Downloading asyncer-0.0.8-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting cachetools>=5.5.0 (from dspy)\n",
      "  Downloading cachetools-6.1.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting cloudpickle>=3.0.0 (from dspy)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting rich>=13.7.1 (from dspy)\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/codespace/.local/lib/python3.12/site-packages (from dspy) (2.2.5)\n",
      "Collecting xxhash>=3.5.0 (from dspy)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting gepa==0.0.4 (from gepa[dspy]==0.0.4->dspy)\n",
      "  Downloading gepa-0.0.4-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting datasets>=2.14.6 (from gepa==0.0.4->gepa[dspy]==0.0.4->dspy)\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.12/site-packages (from anyio->dspy) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/codespace/.local/lib/python3.12/site-packages (from anyio->dspy) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /home/codespace/.local/lib/python3.12/site-packages (from anyio->dspy) (4.13.2)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy) (3.13.1)\n",
      "Collecting pyarrow>=15.0.0 (from datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy)\n",
      "  Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/python/3.12.1/lib/python3.12/site-packages (from datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy) (2.2.2)\n",
      "Collecting multiprocess<0.70.17 (from datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy) (2024.6.1)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy)\n",
      "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.12/site-packages (from datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/codespace/.local/lib/python3.12/site-packages (from datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy) (6.0.2)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy)\n",
      "  Downloading aiohttp-3.12.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy)\n",
      "  Downloading frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy)\n",
      "  Downloading multidict-6.6.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy)\n",
      "  Downloading propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy)\n",
      "  Downloading yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.24.0->datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy)\n",
      "  Downloading hf_xet-1.1.8-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (703 bytes)\n",
      "Collecting click (from litellm>=1.64.0->dspy)\n",
      "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /home/codespace/.local/lib/python3.12/site-packages (from litellm>=1.64.0->dspy) (0.28.1)\n",
      "Collecting importlib-metadata>=6.8.0 (from litellm>=1.64.0->dspy)\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /home/codespace/.local/lib/python3.12/site-packages (from litellm>=1.64.0->dspy) (3.1.6)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /home/codespace/.local/lib/python3.12/site-packages (from litellm>=1.64.0->dspy) (4.23.0)\n",
      "Collecting python-dotenv>=0.2.0 (from litellm>=1.64.0->dspy)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting tiktoken>=0.7.0 (from litellm>=1.64.0->dspy)\n",
      "  Downloading tiktoken-0.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting tokenizers (from litellm>=1.64.0->dspy)\n",
      "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.64.0->dspy) (3.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy) (0.24.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic>=2.0->dspy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic>=2.0->dspy) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from pydantic>=2.0->dspy) (0.4.1)\n",
      "Requirement already satisfied: certifi in /home/codespace/.local/lib/python3.12/site-packages (from httpx>=0.23.0->litellm>=1.64.0->dspy) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /home/codespace/.local/lib/python3.12/site-packages (from httpx>=0.23.0->litellm>=1.64.0->dspy) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/codespace/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.23.0->litellm>=1.64.0->dspy) (0.16.0)\n",
      "Collecting zipp>=3.20 (from importlib-metadata>=6.8.0->litellm>=1.64.0->dspy)\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai>=0.28.1->dspy) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from openai>=0.28.1->dspy) (0.10.0)\n",
      "Collecting alembic>=1.5.0 (from optuna>=3.4.0->dspy)\n",
      "  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorlog (from optuna>=3.4.0->dspy)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna>=3.4.0->dspy)\n",
      "  Downloading sqlalchemy-2.0.43-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna>=3.4.0->dspy)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.31.0->dspy) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.31.0->dspy) (2.4.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=13.7.1->dspy)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.12/site-packages (from rich>=13.7.1->dspy) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=13.7.1->dspy)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting greenlet>=1 (from sqlalchemy>=1.4.2->optuna>=3.4.0->dspy)\n",
      "  Downloading greenlet-3.2.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas->datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.14.6->gepa==0.0.4->gepa[dspy]==0.0.4->dspy) (1.17.0)\n",
      "Downloading dspy-3.0.1-py3-none-any.whl (259 kB)\n",
      "Downloading asyncer-0.0.8-py3-none-any.whl (9.2 kB)\n",
      "Downloading gepa-0.0.4-py3-none-any.whl (35 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading cachetools-6.1.0-py3-none-any.whl (11 kB)\n",
      "Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading aiohttp-3.12.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.6.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
      "Downloading yarl-1.20.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (355 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Downloading frozenlist-1.7.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "Downloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.8-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading json_repair-0.49.0-py3-none-any.whl (26 kB)\n",
      "Downloading litellm-1.75.8-py3-none-any.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading magicattr-0.1.6-py2.py3-none-any.whl (4.7 kB)\n",
      "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
      "Downloading alembic-1.16.4-py3-none-any.whl (247 kB)\n",
      "Downloading propcache-0.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (224 kB)\n",
      "Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading regex-2025.7.34-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (801 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m801.9/801.9 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading sqlalchemy-2.0.43-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.2.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (607 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m607.6/607.6 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading tiktoken-0.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ujson-5.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
      "Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Downloading click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: magicattr, zipp, xxhash, ujson, tenacity, regex, python-dotenv, pyarrow, propcache, multidict, mdurl, Mako, json-repair, hf-xet, greenlet, frozenlist, diskcache, dill, colorlog, cloudpickle, click, cachetools, backoff, aiohappyeyeballs, yarl, tiktoken, sqlalchemy, multiprocess, markdown-it-py, importlib-metadata, huggingface-hub, asyncer, aiosignal, tokenizers, rich, alembic, aiohttp, optuna, litellm, datasets, gepa, dspy\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42/42\u001b[0m [dspy]0m [dspy]0m [datasets]s]-hub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed Mako-1.3.10 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 alembic-1.16.4 asyncer-0.0.8 backoff-2.2.1 cachetools-6.1.0 click-8.2.1 cloudpickle-3.1.1 colorlog-6.9.0 datasets-4.0.0 dill-0.3.8 diskcache-5.6.3 dspy-3.0.1 frozenlist-1.7.0 gepa-0.0.4 greenlet-3.2.4 hf-xet-1.1.8 huggingface-hub-0.34.4 importlib-metadata-8.7.0 json-repair-0.49.0 litellm-1.75.8 magicattr-0.1.6 markdown-it-py-4.0.0 mdurl-0.1.2 multidict-6.6.4 multiprocess-0.70.16 optuna-4.5.0 propcache-0.3.2 pyarrow-21.0.0 python-dotenv-1.1.1 regex-2025.7.34 rich-14.1.0 sqlalchemy-2.0.43 tenacity-9.1.2 tiktoken-0.11.0 tokenizers-0.21.4 ujson-5.10.0 xxhash-3.5.0 yarl-1.20.1 zipp-3.23.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip install dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2eebd6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0f507fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To make API calls to models **other than `gpt-4.0`/`gpt-4.1`** (for example, `gpt-3.5-turbo`, `gpt-4-turbo`, `dall-e-3`, `whisper-1`, etc.) using the **OpenAI Python library**, you simply need to specify the desired model in your API call. **No special access is required for most models** (except for some, like `gpt-4` or `dall-e-3`, which may require you to have billing enabled or be in a waitlist).\n",
       "\n",
       "### 1. Install the OpenAI Python library\n",
       "\n",
       "```bash\n",
       "pip install openai\n",
       "```\n",
       "\n",
       "### 2. Set your API key\n",
       "\n",
       "```python\n",
       "import openai\n",
       "\n",
       "openai.api_key = \"sk-...\"  # Replace with your API key\n",
       "```\n",
       "\n",
       "### 3. Specify the model in your API call\n",
       "\n",
       "#### For Chat Models (e.g., `gpt-3.5-turbo`, `gpt-4-turbo`):\n",
       "\n",
       "```python\n",
       "response = openai.ChatCompletion.create(\n",
       "    model=\"gpt-3.5-turbo\",  # or \"gpt-4-turbo\", \"gpt-4o\", etc.\n",
       "    messages=[\n",
       "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
       "        {\"role\": \"user\", \"content\": \"Hello!\"},\n",
       "    ]\n",
       ")\n",
       "print(response.choices[0].message.content)\n",
       "```\n",
       "\n",
       "#### For Text Completion Models (e.g., `text-davinci-003`):\n",
       "\n",
       "```python\n",
       "response = openai.Completion.create(\n",
       "    model=\"text-davinci-003\",\n",
       "    prompt=\"Once upon a time,\",\n",
       "    max_tokens=50\n",
       ")\n",
       "print(response.choices[0].text)\n",
       "```\n",
       "\n",
       "#### For Image Generation (e.g., `dall-e-3`):\n",
       "\n",
       "```python\n",
       "response = openai.Image.create(\n",
       "    model=\"dall-e-3\",\n",
       "    prompt=\"A futuristic cityscape at sunset\",\n",
       "    n=1,\n",
       "    size=\"1024x1024\"\n",
       ")\n",
       "print(response['data'][0]['url'])\n",
       "```\n",
       "\n",
       "#### For Audio Transcription (e.g., `whisper-1`):\n",
       "\n",
       "```python\n",
       "audio_file = open(\"audio.mp3\", \"rb\")\n",
       "transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
       "print(transcript[\"text\"])\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "## **How to know which models you have access to?**\n",
       "\n",
       "You can list available models with:\n",
       "\n",
       "```python\n",
       "models = openai.Model.list()\n",
       "for model in models['data']:\n",
       "    print(model['id'])\n",
       "```\n",
       "\n",
       "---\n",
       "\n",
       "## **Notes:**\n",
       "\n",
       "- **Some models (like `gpt-4`, `dall-e-3`) may require you to have a paid account or be on a waitlist.** If you get an error like `You do not have access to this model`, check your account status or upgrade.\n",
       "- **Always check the [OpenAI API documentation](https://platform.openai.com/docs/models/overview)** for the latest model names and access requirements.\n",
       "- **The model name is specified in the `model` parameter** of your API call.\n",
       "\n",
       "---\n",
       "\n",
       "**In summary:**  \n",
       "You do **not** need to do anything special to access other models, just specify the model name in your API call, as long as your account has access to it. If you get an access error, check your account or billing status."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dspy\n",
    "\n",
    "# Create a DSPY language model object using the OpenAI client\n",
    "lm = dspy.LM(\n",
    "    model=\"gpt-4.1\",         # or another available model\n",
    "    api_key=client.api_key,        # reuse the api_key from your OpenAI client\n",
    "    provider=\"openai\"              # specify the provider\n",
    ")\n",
    "\n",
    "# Example prompt\n",
    "prompt = \"What is the capital of France in 500BC?\"\n",
    "prompt = \"How do I get access to make api calls to models other than gp-4.1 on openai via python OpenAI?\"\n",
    "\n",
    "# Call the language model\n",
    "response = lm(prompt)\n",
    "\n",
    "md(response[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

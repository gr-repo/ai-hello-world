{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df967dde",
   "metadata": {},
   "source": [
    "# Prompt Optimisation Using MIPRO\n",
    "\n",
    "This method, MIPRO, rewrites the prompt. So start with a simple vague prompt and get it re-written to something that fits. \n",
    "\n",
    "Use Case:  \n",
    "Create Meal/Dish classes with a prompt that is vague to start off with (i.e. \"Create a meal\"). Then put in a constraint that it only knows about during the optimisation phase (i.e. \"Only select Fish dishes\"). Then optimise the prompt and see if it changes it to cater for this constraint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86043947",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Note: Update OPENAI_API_KEY in env settings or MySettings class, see repo's README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e6bbc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting keys from environment variables\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import dspy \n",
    "from common.my_settings import MySettings  \n",
    "from common.utils import md\n",
    "from common.llm_client_factory import LlmClientFactory\n",
    "from dspy_utils.dspy_helpers import md_dspy\n",
    "\n",
    "settings = MySettings().get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a497e0a",
   "metadata": {},
   "source": [
    "# Create Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8a873b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create domain classes\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from typing import Literal\n",
    "\n",
    "class Dish(BaseModel):\n",
    "    # Output\n",
    "    dish_type: Literal[\"Fish\", \"Vegetarian\", \"Chicken\"] = dspy.OutputField() # This field is locked to a range of the Literal\n",
    "    name: str = dspy.OutputField()\n",
    "    \n",
    "class Meal(dspy.Signature):\n",
    "    \n",
    "    dish_suggestion = dspy.InputField(\"Suggest a meal for the given day of the week.\")\n",
    "\n",
    "    # Outputs\n",
    "    dish: Dish = dspy.OutputField()\n",
    "    day_of_the_week: Literal[\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"] = dspy.OutputField()\n",
    "\n",
    "#class MealGenerator(dspy.Signature):\n",
    "    \n",
    "\n",
    "# class MealGenerator(dspy.Module):\n",
    "#     def __init__(self):\n",
    "#         self.prompt = dspy.Predict(Meal)\n",
    "\n",
    "#     def forward(self):\n",
    "#         return self.prompt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb80c38",
   "metadata": {},
   "source": [
    "# Create Trainset\n",
    "The ideal number of trainset examples for the DSPy MIPRO Prompt Optimizer depends on the complexity of your task and the variability in your data. However, here are some general guidelines:\n",
    "\n",
    "Recommended Starting Point\n",
    "1. Small-scale tasks or prototyping: Start with **20–50 examples**.\n",
    "1. Medium complexity tasks: Use **100–500 examples**.\n",
    "1. High variability or complex tasks: Consider **1,000+ examples**, if computationally feasible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30500874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat trainset with 25 examples. \n",
    "# Tip: Use ChatGPT to generate these examples for you.\n",
    "\n",
    "trainset = [\n",
    "    {'preferred_day': 'Tuesday', 'dish': {'dish_type': 'Chicken', 'name': 'Chicken Tikka Masala'}, 'day_of_the_week': 'Tuesday'},\n",
    "    {'preferred_day': 'Monday', 'dish': {'dish_type': 'Vegetarian', 'name': 'Caprese Salad'}, 'day_of_the_week': 'Monday'},\n",
    "    {'preferred_day': 'Monday', 'dish': {'dish_type': 'Fish', 'name': 'Baked Cod'}, 'day_of_the_week': 'Monday'},\n",
    "    {'preferred_day': 'Friday', 'dish': {'dish_type': 'Chicken', 'name': 'Chicken Alfredo'}, 'day_of_the_week': 'Friday'},\n",
    "    {'preferred_day': 'Sunday', 'dish': {'dish_type': 'Vegetarian', 'name': 'Chickpea Curry'}, 'day_of_the_week': 'Sunday'},\n",
    "    {'preferred_day': 'Thursday', 'dish': {'dish_type': 'Chicken', 'name': 'Chicken Tikka Masala'}, 'day_of_the_week': 'Thursday'},\n",
    "    {'preferred_day': 'Monday', 'dish': {'dish_type': 'Vegetarian', 'name': 'Caprese Salad'}, 'day_of_the_week': 'Monday'},\n",
    "    {'preferred_day': 'Friday', 'dish': {'dish_type': 'Chicken', 'name': 'Grilled Chicken Salad'}, 'day_of_the_week': 'Friday'},\n",
    "    {'preferred_day': 'Saturday', 'dish': {'dish_type': 'Vegetarian', 'name': 'Vegetable Stir Fry'}, 'day_of_the_week': 'Saturday'},\n",
    "    {'preferred_day': 'Monday', 'dish': {'dish_type': 'Fish', 'name': 'Baked Cod'}, 'day_of_the_week': 'Monday'},\n",
    "    {'preferred_day': 'Thursday', 'dish': {'dish_type': 'Vegetarian', 'name': 'Lentil Soup'}, 'day_of_the_week': 'Thursday'},\n",
    "    {'preferred_day': 'Friday', 'dish': {'dish_type': 'Fish', 'name': 'Fish Tacos'}, 'day_of_the_week': 'Friday'},\n",
    "    {'preferred_day': 'Wednesday', 'dish': {'dish_type': 'Vegetarian', 'name': 'Vegetable Stir Fry'}, 'day_of_the_week': 'Wednesday'},\n",
    "    {'preferred_day': 'Tuesday', 'dish': {'dish_type': 'Fish', 'name': 'Baked Cod'}, 'day_of_the_week': 'Tuesday'},\n",
    "    {'preferred_day': 'Saturday', 'dish': {'dish_type': 'Vegetarian', 'name': 'Chickpea Curry'}, 'day_of_the_week': 'Saturday'},\n",
    "    {'preferred_day': 'Tuesday', 'dish': {'dish_type': 'Chicken', 'name': 'Chicken Noodle Soup'}, 'day_of_the_week': 'Tuesday'},\n",
    "    {'preferred_day': 'Wednesday', 'dish': {'dish_type': 'Vegetarian', 'name': 'Mushroom Risotto'}, 'day_of_the_week': 'Wednesday'},\n",
    "    {'preferred_day': 'Sunday', 'dish': {'dish_type': 'Chicken', 'name': 'Grilled Chicken Salad'}, 'day_of_the_week': 'Sunday'},\n",
    "    {'preferred_day': 'Wednesday', 'dish': {'dish_type': 'Chicken', 'name': 'BBQ Chicken'}, 'day_of_the_week': 'Wednesday'},\n",
    "    {'preferred_day': 'Sunday', 'dish': {'dish_type': 'Chicken', 'name': 'Grilled Chicken Salad'}, 'day_of_the_week': 'Sunday'},\n",
    "    {'preferred_day': 'Thursday', 'dish': {'dish_type': 'Chicken', 'name': 'Chicken Tikka Masala'}, 'day_of_the_week': 'Thursday'},\n",
    "    {'preferred_day': 'Wednesday', 'dish': {'dish_type': 'Fish', 'name': 'Baked Cod'}, 'day_of_the_week': 'Wednesday'},\n",
    "    {'preferred_day': 'Wednesday', 'dish': {'dish_type': 'Fish', 'name': 'Grilled Salmon'}, 'day_of_the_week': 'Wednesday'},\n",
    "    {'preferred_day': 'Thursday', 'dish': {'dish_type': 'Chicken', 'name': 'BBQ Chicken'}, 'day_of_the_week': 'Thursday'},\n",
    "    {'preferred_day': 'Wednesday', 'dish': {'dish_type': 'Chicken', 'name': 'BBQ Chicken'}, 'day_of_the_week': 'Wednesday'}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479b2fb8",
   "metadata": {},
   "source": [
    "# Creat LLM Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83a32205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smaller LLM, this is the one that we are trying to optimize for, the prompts are going to be tweaked\n",
    "# to get the best out of this model\n",
    "lm_gpt35 = dspy.LM('gpt-3.5-turbo', model_type='chat', cache=False, api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "#dspy.configure(lm=lm_gpt35)\n",
    "\n",
    "# # Larger LLM, this is the one that we are going to use to optimize the prompts\n",
    "# # It will be the helper/teach/AI Judge to assist in the optimization process\n",
    "lm_gpt4 = dspy.LM('gpt-4.1', model_type='chat', cache=False, api_key=settings.OPENAI_API_KEY)\n",
    "dspy.configure(lm=lm_gpt4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a162017c",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "\n",
    "Purpose of metric in MIPRO\n",
    "The metric function in MIPRO is used to evaluate the quality of a model’s output against the expected result. It should return a boolean or score indicating whether the output is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188f3e7f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f9ec6b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (expected.dish.dish_type == \u001b[33m\"\u001b[39m\u001b[33mFish\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m matcher = dspy.Predict(Meal)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m md(\u001b[43mmatcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMeal\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/dspy/predict/predict.py:84\u001b[39m, in \u001b[36mPredict.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m     83\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m args:\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_positional_args_error_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     86\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m(**kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/python/3.12.1/lib/python3.12/site-packages/dspy/predict/predict.py:79\u001b[39m, in \u001b[36mPredict._get_positional_args_error_message\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_positional_args_error_message\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     75\u001b[39m     input_fields = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.signature.input_fields.keys())\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m     77\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPositional arguments are not allowed when calling `dspy.Predict`, must use keyword arguments \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     78\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mthat match your signature input fields: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(input_fields)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. For example: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`predict(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43minput_fields\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=input_value, ...)`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     80\u001b[39m     )\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "def validate_match(expected: Meal, actual: Meal) -> bool:\n",
    "    return (expected.dish.dish_type == \"Fish\")\n",
    "\n",
    "matcher = dspy.Predict(Meal)\n",
    "md(matcher(Meal))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec6e53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.teleprompt import *\n",
    "\n",
    "\n",
    "tp = dspy.MIPROv2(metric=validate_match, auto=\"light\", prompt_model=lm_gpt35, task_model=lm_gpt4)\n",
    "optimized_matcher = tp.compile(matcher, trainset=trainset, requires_permission_to_run=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059aacb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting keys from environment variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/04 18:32:57 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "RUNNING WITH THE FOLLOWING MEDIUM AUTO RUN SETTINGS:\n",
      "num_trials: 18\n",
      "minibatch: False\n",
      "num_fewshot_candidates: 12\n",
      "num_instruct_candidates: 6\n",
      "valset size: 6\n",
      "\n",
      "2025/09/04 18:32:57 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
      "2025/09/04 18:32:57 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
      "\n",
      "2025/09/04 18:32:57 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=12 sets of demonstrations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping set 1/12\n",
      "Bootstrapping set 2/12\n",
      "Bootstrapping set 3/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Bootstrapping set 4/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Bootstrapping set 5/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Bootstrapping set 6/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Bootstrapping set 7/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Bootstrapping set 8/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Bootstrapping set 9/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Bootstrapping set 10/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Bootstrapping set 11/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Bootstrapping set 12/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.01it/s]\n",
      "2025/09/04 18:33:13 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
      "2025/09/04 18:33:13 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 0 full traces after 1 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "SOURCE CODE: \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/04 18:33:15 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "Proposing N=6 instructions...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA SUMMARY: The dataset contains examples with a `number_guess` input represented as a string and its corresponding textual `answer`. There is a clear pattern where the `number_guess` is converted into its textual equivalent.\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: persona\n",
      "PROGRAM DESCRIPTION: The program is designed to be a pipeline for solving tasks using calls to language models. It likely takes in input data, processes it using language models, and provides an output based on the task at hand. This pipeline can be used for various natural language processing tasks such as text classification, sentiment analysis, language translation, and more. The program leverages the capabilities of language models to automate and improve the efficiency of various text-related tasks.\n",
      "task_demos No task demos provided.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-09-04T18:33:20.430023]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `dataset_description` (str): A description of the dataset that we are using.\n",
      "2. `program_code` (str): Language model program designed to solve a particular task.\n",
      "3. `program_description` (str): Summary of the task the program is designed to solve, and how it goes about solving it.\n",
      "4. `module` (str): The module to create an instruction for.\n",
      "5. `module_description` (str): Description of the module to create an instruction for.\n",
      "6. `task_demos` (str): Example inputs/outputs of our module.\n",
      "7. `basic_instruction` (str): Basic instruction.\n",
      "8. `tip` (str): A suggestion for how to go about generating the new instruction.\n",
      "Your output fields are:\n",
      "1. `proposed_instruction` (str): Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "{dataset_description}\n",
      "\n",
      "[[ ## program_code ## ]]\n",
      "{program_code}\n",
      "\n",
      "[[ ## program_description ## ]]\n",
      "{program_description}\n",
      "\n",
      "[[ ## module ## ]]\n",
      "{module}\n",
      "\n",
      "[[ ## module_description ## ]]\n",
      "{module_description}\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "{task_demos}\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "{basic_instruction}\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "{tip}\n",
      "\n",
      "[[ ## proposed_instruction ## ]]\n",
      "{proposed_instruction}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "The dataset contains examples with a `number_guess` input represented as a string and its corresponding textual `answer`. There is a clear pattern where the `number_guess` is converted into its textual equivalent.\n",
      "\n",
      "[[ ## program_code ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[ ## program_description ## ]]\n",
      "The program is designed to be a pipeline for solving tasks using calls to language models. It likely takes in input data, processes it using language models, and provides an output based on the task at hand. This pipeline can be used for various natural language processing tasks such as text classification, sentiment analysis, language translation, and more. The program leverages the capabilities of language models to automate and improve the efficiency of various text-related tasks.\n",
      "\n",
      "[[ ## module ## ]]\n",
      "Predict(number_guess) -> answer\n",
      "\n",
      "[[ ## module_description ## ]]\n",
      "The `Predict` module in this pipeline takes a `number_guess` as input and returns an `answer`. This module likely utilizes a language model to predict or generate a response based on the input `number_guess`. The specific details of how the prediction is made would depend on the task at hand, such as predicting the next word in a sequence, generating a completion, or providing a numerical prediction. The `Predict` module plays a crucial role in leveraging language models to make informed predictions or generate outputs based on the input data.\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "No task demos provided.\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "Guess a number from 1 to 3\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "Include a persona that is relevant to the task in the instruction (ie. \"You are a ...\")\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## proposed_instruction ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## proposed_instruction ## ]]\n",
      "You are a fortune teller. Predict the corresponding answer based on the number guess provided (1 to 3).\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: You are a fortune teller. Predict the corresponding answer based on the number guess provided (1 to 3).\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: simple\n",
      "PROGRAM DESCRIPTION: The provided pseudocode appears to be a pipeline designed to solve tasks using language models. It likely involves integrating different language models or processing steps to perform a specific task efficiently. The program seems to orchestrate the flow of data through various language models or processing components to achieve a desired outcome.\n",
      "task_demos No task demos provided.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-09-04T18:33:24.083242]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `dataset_description` (str): A description of the dataset that we are using.\n",
      "2. `program_code` (str): Language model program designed to solve a particular task.\n",
      "3. `program_description` (str): Summary of the task the program is designed to solve, and how it goes about solving it.\n",
      "4. `module` (str): The module to create an instruction for.\n",
      "5. `module_description` (str): Description of the module to create an instruction for.\n",
      "6. `task_demos` (str): Example inputs/outputs of our module.\n",
      "7. `basic_instruction` (str): Basic instruction.\n",
      "8. `tip` (str): A suggestion for how to go about generating the new instruction.\n",
      "Your output fields are:\n",
      "1. `proposed_instruction` (str): Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "{dataset_description}\n",
      "\n",
      "[[ ## program_code ## ]]\n",
      "{program_code}\n",
      "\n",
      "[[ ## program_description ## ]]\n",
      "{program_description}\n",
      "\n",
      "[[ ## module ## ]]\n",
      "{module}\n",
      "\n",
      "[[ ## module_description ## ]]\n",
      "{module_description}\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "{task_demos}\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "{basic_instruction}\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "{tip}\n",
      "\n",
      "[[ ## proposed_instruction ## ]]\n",
      "{proposed_instruction}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "The dataset contains examples with a `number_guess` input represented as a string and its corresponding textual `answer`. There is a clear pattern where the `number_guess` is converted into its textual equivalent.\n",
      "\n",
      "[[ ## program_code ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[ ## program_description ## ]]\n",
      "The provided pseudocode appears to be a pipeline designed to solve tasks using language models. It likely involves integrating different language models or processing steps to perform a specific task efficiently. The program seems to orchestrate the flow of data through various language models or processing components to achieve a desired outcome.\n",
      "\n",
      "[[ ## module ## ]]\n",
      "Predict(number_guess) -> answer\n",
      "\n",
      "[[ ## module_description ## ]]\n",
      "The `Predict` module in the pipeline is responsible for taking a `number_guess` as input and producing an `answer` as output. This module likely utilizes a language model or a predictive model to generate a response based on the provided `number_guess`. It plays a crucial role in the task-solving process by making predictions or providing insights based on the input data.\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "No task demos provided.\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "Guess a number from 1 to 3\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "Keep the instruction clear and concise.\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## proposed_instruction ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## proposed_instruction ## ]]\n",
      "Based on the dataset examples where a `number_guess` is converted into its corresponding `answer`, please predict the textual answer for the given `number_guess`.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: Based on the dataset examples where a `number_guess` is converted into its corresponding `answer`, please predict the textual answer for the given `number_guess`.\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: creative\n",
      "PROGRAM DESCRIPTION: The provided pseudocode appears to be for a pipeline that utilizes language models to solve a specific task. It likely involves processing input data using language models and generating some form of output based on the model's predictions or analysis.\n",
      "task_demos No task demos provided.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-09-04T18:33:26.819477]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `dataset_description` (str): A description of the dataset that we are using.\n",
      "2. `program_code` (str): Language model program designed to solve a particular task.\n",
      "3. `program_description` (str): Summary of the task the program is designed to solve, and how it goes about solving it.\n",
      "4. `module` (str): The module to create an instruction for.\n",
      "5. `module_description` (str): Description of the module to create an instruction for.\n",
      "6. `task_demos` (str): Example inputs/outputs of our module.\n",
      "7. `basic_instruction` (str): Basic instruction.\n",
      "8. `tip` (str): A suggestion for how to go about generating the new instruction.\n",
      "Your output fields are:\n",
      "1. `proposed_instruction` (str): Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "{dataset_description}\n",
      "\n",
      "[[ ## program_code ## ]]\n",
      "{program_code}\n",
      "\n",
      "[[ ## program_description ## ]]\n",
      "{program_description}\n",
      "\n",
      "[[ ## module ## ]]\n",
      "{module}\n",
      "\n",
      "[[ ## module_description ## ]]\n",
      "{module_description}\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "{task_demos}\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "{basic_instruction}\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "{tip}\n",
      "\n",
      "[[ ## proposed_instruction ## ]]\n",
      "{proposed_instruction}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "The dataset contains examples with a `number_guess` input represented as a string and its corresponding textual `answer`. There is a clear pattern where the `number_guess` is converted into its textual equivalent.\n",
      "\n",
      "[[ ## program_code ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[ ## program_description ## ]]\n",
      "The provided pseudocode appears to be for a pipeline that utilizes language models to solve a specific task. It likely involves processing input data using language models and generating some form of output based on the model's predictions or analysis.\n",
      "\n",
      "[[ ## module ## ]]\n",
      "Predict(number_guess) -> answer\n",
      "\n",
      "[[ ## module_description ## ]]\n",
      "The `Predict` module in the pipeline takes a `number_guess` as input and returns an `answer` based on the predictions made by the language model. This module is responsible for utilizing the language model to generate predictions or responses related to the task at hand. It likely involves processing the `number_guess` through the language model and providing an output that corresponds to the model's analysis or prediction.\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "No task demos provided.\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "Guess a number from 1 to 3\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "Don't be afraid to be creative when creating the new instruction!\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## proposed_instruction ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## proposed_instruction ## ]]\n",
      "Given a `number_guess` as a string input, use the language model to predict and generate the corresponding textual `answer`.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: Given a `number_guess` as a string input, use the language model to predict and generate the corresponding textual `answer`.\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: description\n",
      "PROGRAM DESCRIPTION: The program appears to be a pseudocode for a language model program designed to solve tasks by utilizing calls to language models. It likely incorporates the use of pre-trained language models to perform various natural language processing tasks such as text generation, sentiment analysis, question answering, and more. The program is structured to interact with language models to process and analyze text data for a wide range of applications.\n",
      "task_demos No task demos provided.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-09-04T18:33:31.574205]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `dataset_description` (str): A description of the dataset that we are using.\n",
      "2. `program_code` (str): Language model program designed to solve a particular task.\n",
      "3. `program_description` (str): Summary of the task the program is designed to solve, and how it goes about solving it.\n",
      "4. `module` (str): The module to create an instruction for.\n",
      "5. `module_description` (str): Description of the module to create an instruction for.\n",
      "6. `task_demos` (str): Example inputs/outputs of our module.\n",
      "7. `basic_instruction` (str): Basic instruction.\n",
      "8. `tip` (str): A suggestion for how to go about generating the new instruction.\n",
      "Your output fields are:\n",
      "1. `proposed_instruction` (str): Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "{dataset_description}\n",
      "\n",
      "[[ ## program_code ## ]]\n",
      "{program_code}\n",
      "\n",
      "[[ ## program_description ## ]]\n",
      "{program_description}\n",
      "\n",
      "[[ ## module ## ]]\n",
      "{module}\n",
      "\n",
      "[[ ## module_description ## ]]\n",
      "{module_description}\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "{task_demos}\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "{basic_instruction}\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "{tip}\n",
      "\n",
      "[[ ## proposed_instruction ## ]]\n",
      "{proposed_instruction}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "The dataset contains examples with a `number_guess` input represented as a string and its corresponding textual `answer`. There is a clear pattern where the `number_guess` is converted into its textual equivalent.\n",
      "\n",
      "[[ ## program_code ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[ ## program_description ## ]]\n",
      "The program appears to be a pseudocode for a language model program designed to solve tasks by utilizing calls to language models. It likely incorporates the use of pre-trained language models to perform various natural language processing tasks such as text generation, sentiment analysis, question answering, and more. The program is structured to interact with language models to process and analyze text data for a wide range of applications.\n",
      "\n",
      "[[ ## module ## ]]\n",
      "Predict(number_guess) -> answer\n",
      "\n",
      "[[ ## module_description ## ]]\n",
      "The `Predict` module in the program is designed to take a `number_guess` as input and provide an `answer` based on some prediction or inference process. This module likely interfaces with a language model to make predictions or generate responses related to the input number_guess. It could be used for tasks such as predicting the next number in a sequence, forecasting trends based on numerical data, or any other scenario where a predictive model is required to generate an answer based on a numerical input.\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "No task demos provided.\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "Guess a number from 1 to 3\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "Make sure your instruction is very informative and descriptive.\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## proposed_instruction ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## proposed_instruction ## ]]\n",
      "Given a `number_guess` input represented as a string, provide the corresponding textual `answer` by utilizing the Predict module in the program. The Predict module is designed to make predictions or generate responses based on the input `number_guess`.\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: Given a `number_guess` input represented as a string, provide the corresponding textual `answer` by utilizing the Predict module in the program. The Predict module is designed to make predictions or generate responses based on the input `number_guess`.\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: simple\n",
      "PROGRAM DESCRIPTION: The program appears to be designed to solve tasks using a pipeline that involves calls to language models. It likely takes input data, processes it through various language models, and produces an output based on the combined results of these models. This pipeline could be used for tasks such as text generation, sentiment analysis, language translation, or any other natural language processing task that can benefit from the use of language models.\n",
      "task_demos No task demos provided.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-09-04T18:33:35.311017]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `dataset_description` (str): A description of the dataset that we are using.\n",
      "2. `program_code` (str): Language model program designed to solve a particular task.\n",
      "3. `program_description` (str): Summary of the task the program is designed to solve, and how it goes about solving it.\n",
      "4. `module` (str): The module to create an instruction for.\n",
      "5. `module_description` (str): Description of the module to create an instruction for.\n",
      "6. `task_demos` (str): Example inputs/outputs of our module.\n",
      "7. `basic_instruction` (str): Basic instruction.\n",
      "8. `tip` (str): A suggestion for how to go about generating the new instruction.\n",
      "Your output fields are:\n",
      "1. `proposed_instruction` (str): Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "{dataset_description}\n",
      "\n",
      "[[ ## program_code ## ]]\n",
      "{program_code}\n",
      "\n",
      "[[ ## program_description ## ]]\n",
      "{program_description}\n",
      "\n",
      "[[ ## module ## ]]\n",
      "{module}\n",
      "\n",
      "[[ ## module_description ## ]]\n",
      "{module_description}\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "{task_demos}\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "{basic_instruction}\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "{tip}\n",
      "\n",
      "[[ ## proposed_instruction ## ]]\n",
      "{proposed_instruction}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "The dataset contains examples with a `number_guess` input represented as a string and its corresponding textual `answer`. There is a clear pattern where the `number_guess` is converted into its textual equivalent.\n",
      "\n",
      "[[ ## program_code ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[ ## program_description ## ]]\n",
      "The program appears to be designed to solve tasks using a pipeline that involves calls to language models. It likely takes input data, processes it through various language models, and produces an output based on the combined results of these models. This pipeline could be used for tasks such as text generation, sentiment analysis, language translation, or any other natural language processing task that can benefit from the use of language models.\n",
      "\n",
      "[[ ## module ## ]]\n",
      "Predict(number_guess) -> answer\n",
      "\n",
      "[[ ## module_description ## ]]\n",
      "The `Predict` module in the pipeline takes a `number_guess` as input and returns an `answer`. This module is likely responsible for utilizing a language model to predict or generate an answer based on the given `number_guess`. Depending on the specific task, the language model could be trained to predict the next number in a sequence, guess a number based on contextual information, or generate a number that fits certain criteria.\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "No task demos provided.\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "Guess a number from 1 to 3\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "Keep the instruction clear and concise.\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## proposed_instruction ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## proposed_instruction ## ]]\n",
      "Predict the textual answer corresponding to the given number_guess.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: Predict the textual answer corresponding to the given number_guess.\n",
      "Using a randomly generated configuration for our grounded proposer.\n",
      "Selected tip: description\n",
      "PROGRAM DESCRIPTION: The program appears to be designed to solve a task by utilizing a pipeline that involves making calls to language models. It likely takes input data, processes it through various language models, and generates an output based on the combined results of these models. This pipeline may involve tasks such as text generation, sentiment analysis, language translation, or any other natural language processing task that can be addressed using language models.\n",
      "task_demos No task demos provided.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/04 18:33:40 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
      "\n",
      "2025/09/04 18:33:40 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Guess a number from 1 to 3\n",
      "\n",
      "2025/09/04 18:33:40 INFO dspy.teleprompt.mipro_optimizer_v2: 1: Based on the dataset examples where a `number_guess` is converted into its corresponding `answer`, please predict the textual answer for the given `number_guess`.\n",
      "\n",
      "2025/09/04 18:33:40 INFO dspy.teleprompt.mipro_optimizer_v2: 2: Given a `number_guess` as a string input, use the language model to predict and generate the corresponding textual `answer`.\n",
      "\n",
      "2025/09/04 18:33:40 INFO dspy.teleprompt.mipro_optimizer_v2: 3: Given a `number_guess` input represented as a string, provide the corresponding textual `answer` by utilizing the Predict module in the program. The Predict module is designed to make predictions or generate responses based on the input `number_guess`.\n",
      "\n",
      "2025/09/04 18:33:40 INFO dspy.teleprompt.mipro_optimizer_v2: 4: Predict the textual answer corresponding to the given number_guess.\n",
      "\n",
      "2025/09/04 18:33:40 INFO dspy.teleprompt.mipro_optimizer_v2: 5: Given a `number_guess` as a string input, use the language models in the pipeline to predict and generate the corresponding textual `answer` based on the pattern observed in the dataset where the `number_guess` is converted into its textual equivalent.\n",
      "\n",
      "2025/09/04 18:33:40 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/09/04 18:33:40 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
      "2025/09/04 18:33:40 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
      "\n",
      "2025/09/04 18:33:40 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 1 / 18 - Full Evaluation of Default Program ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-09-04T18:33:40.194738]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `dataset_description` (str): A description of the dataset that we are using.\n",
      "2. `program_code` (str): Language model program designed to solve a particular task.\n",
      "3. `program_description` (str): Summary of the task the program is designed to solve, and how it goes about solving it.\n",
      "4. `module` (str): The module to create an instruction for.\n",
      "5. `module_description` (str): Description of the module to create an instruction for.\n",
      "6. `task_demos` (str): Example inputs/outputs of our module.\n",
      "7. `basic_instruction` (str): Basic instruction.\n",
      "8. `tip` (str): A suggestion for how to go about generating the new instruction.\n",
      "Your output fields are:\n",
      "1. `proposed_instruction` (str): Propose an instruction that will be used to prompt a Language Model to perform this task.\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "{dataset_description}\n",
      "\n",
      "[[ ## program_code ## ]]\n",
      "{program_code}\n",
      "\n",
      "[[ ## program_description ## ]]\n",
      "{program_description}\n",
      "\n",
      "[[ ## module ## ]]\n",
      "{module}\n",
      "\n",
      "[[ ## module_description ## ]]\n",
      "{module_description}\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "{task_demos}\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "{basic_instruction}\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "{tip}\n",
      "\n",
      "[[ ## proposed_instruction ## ]]\n",
      "{proposed_instruction}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Use the information below to learn about a task that we are trying to solve using calls to an LM, then generate a new instruction that will be used to prompt a Language Model to better solve the task.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## dataset_description ## ]]\n",
      "The dataset contains examples with a `number_guess` input represented as a string and its corresponding textual `answer`. There is a clear pattern where the `number_guess` is converted into its textual equivalent.\n",
      "\n",
      "[[ ## program_code ## ]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[ ## program_description ## ]]\n",
      "The program appears to be designed to solve a task by utilizing a pipeline that involves making calls to language models. It likely takes input data, processes it through various language models, and generates an output based on the combined results of these models. This pipeline may involve tasks such as text generation, sentiment analysis, language translation, or any other natural language processing task that can be addressed using language models.\n",
      "\n",
      "[[ ## module ## ]]\n",
      "Predict(number_guess) -> answer\n",
      "\n",
      "[[ ## module_description ## ]]\n",
      "The `Predict` module in this pipeline takes a `number_guess` as input and generates an `answer` based on the processing done by the language models in the pipeline. This module likely involves using language models to predict or generate a response related to the input `number_guess`. Depending on the specifics of the task, the `Predict` module could be responsible for tasks like predicting the next number in a sequence, generating a number based on certain criteria, or any other number-related prediction task that can be tackled using language models.\n",
      "\n",
      "[[ ## task_demos ## ]]\n",
      "No task demos provided.\n",
      "\n",
      "[[ ## basic_instruction ## ]]\n",
      "Guess a number from 1 to 3\n",
      "\n",
      "[[ ## tip ## ]]\n",
      "Make sure your instruction is very informative and descriptive.\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## proposed_instruction ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## proposed_instruction ## ]]\n",
      "Given a `number_guess` as a string input, use the language models in the pipeline to predict and generate the corresponding textual `answer` based on the pattern observed in the dataset where the `number_guess` is converted into its textual equivalent.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PROPOSED INSTRUCTION: Given a `number_guess` as a string input, use the language models in the pipeline to predict and generate the corresponding textual `answer` based on the pattern observed in the dataset where the `number_guess` is converted into its textual equivalent.\n",
      "Average Metric: 4.00 / 6 (66.7%): 100%|██████████| 6/6 [00:01<00:00,  5.70it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/04 18:33:41 INFO dspy.evaluate.evaluate: Average Metric: 4 / 6 (66.7%)\n",
      "2025/09/04 18:33:41 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 66.67\n",
      "\n",
      "2025/09/04 18:33:41 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 2 / 18 =====\n",
      "2025/09/04 18:33:41 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictor 0\n",
      "i: Based on the dataset examples where a `number_guess` is converted into its corresponding `answer`, please predict the textual answer for the given `number_guess`.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "Average Metric: 4.00 / 6 (66.7%): 100%|██████████| 6/6 [00:00<00:00,  7.49it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/04 18:33:42 INFO dspy.evaluate.evaluate: Average Metric: 4 / 6 (66.7%)\n",
      "2025/09/04 18:33:42 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 66.67 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 6'].\n",
      "2025/09/04 18:33:42 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.67, 66.67]\n",
      "2025/09/04 18:33:42 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 66.67\n",
      "2025/09/04 18:33:42 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/09/04 18:33:42 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 3 / 18 =====\n",
      "2025/09/04 18:33:42 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictor 0\n",
      "i: Predict the textual answer corresponding to the given number_guess.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "Average Metric: 4.00 / 6 (66.7%): 100%|██████████| 6/6 [00:01<00:00,  4.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/04 18:33:43 INFO dspy.evaluate.evaluate: Average Metric: 4 / 6 (66.7%)\n",
      "2025/09/04 18:33:43 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 66.67 with parameters ['Predictor 0: Instruction 4', 'Predictor 0: Few-Shot Set 2'].\n",
      "2025/09/04 18:33:43 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.67, 66.67, 66.67]\n",
      "2025/09/04 18:33:43 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 66.67\n",
      "2025/09/04 18:33:43 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/09/04 18:33:43 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 4 / 18 =====\n",
      "2025/09/04 18:33:43 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictor 0\n",
      "i: Guess a number from 1 to 3\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "Average Metric: 4.00 / 6 (66.7%): 100%|██████████| 6/6 [00:01<00:00,  3.88it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/04 18:33:45 INFO dspy.evaluate.evaluate: Average Metric: 4 / 6 (66.7%)\n",
      "2025/09/04 18:33:45 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 66.67 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 6'].\n",
      "2025/09/04 18:33:45 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.67, 66.67, 66.67, 66.67]\n",
      "2025/09/04 18:33:45 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 66.67\n",
      "2025/09/04 18:33:45 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/09/04 18:33:45 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 5 / 18 =====\n",
      "2025/09/04 18:33:45 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictor 0\n",
      "i: Given a `number_guess` as a string input, use the language model to predict and generate the corresponding textual `answer`.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "Average Metric: 4.00 / 6 (66.7%): 100%|██████████| 6/6 [00:04<00:00,  1.32it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/04 18:33:49 INFO dspy.evaluate.evaluate: Average Metric: 4 / 6 (66.7%)\n",
      "2025/09/04 18:33:49 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 66.67 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 4'].\n",
      "2025/09/04 18:33:49 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.67, 66.67, 66.67, 66.67, 66.67]\n",
      "2025/09/04 18:33:49 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 66.67\n",
      "2025/09/04 18:33:49 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/09/04 18:33:49 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 6 / 18 =====\n",
      "2025/09/04 18:33:49 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictor 0\n",
      "i: Given a `number_guess` input represented as a string, provide the corresponding textual `answer` by utilizing the Predict module in the program. The Predict module is designed to make predictions or generate responses based on the input `number_guess`.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "Average Metric: 4.00 / 6 (66.7%): 100%|██████████| 6/6 [00:00<00:00,  7.05it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/04 18:33:50 INFO dspy.evaluate.evaluate: Average Metric: 4 / 6 (66.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/04 18:33:50 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 66.67 with parameters ['Predictor 0: Instruction 3', 'Predictor 0: Few-Shot Set 5'].\n",
      "2025/09/04 18:33:50 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.67, 66.67, 66.67, 66.67, 66.67, 66.67]\n",
      "2025/09/04 18:33:50 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 66.67\n",
      "2025/09/04 18:33:50 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/09/04 18:33:50 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 7 / 18 =====\n",
      "2025/09/04 18:33:50 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictor 0\n",
      "i: Predict the textual answer corresponding to the given number_guess.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "Average Metric: 4.00 / 6 (66.7%): 100%|██████████| 6/6 [00:03<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/04 18:33:54 INFO dspy.evaluate.evaluate: Average Metric: 4 / 6 (66.7%)\n",
      "2025/09/04 18:33:54 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 66.67 with parameters ['Predictor 0: Instruction 4', 'Predictor 0: Few-Shot Set 6'].\n",
      "2025/09/04 18:33:54 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67]\n",
      "2025/09/04 18:33:54 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 66.67\n",
      "2025/09/04 18:33:54 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/09/04 18:33:54 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 8 / 18 =====\n",
      "2025/09/04 18:33:54 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictor 0\n",
      "i: Given a `number_guess` as a string input, use the language models in the pipeline to predict and generate the corresponding textual `answer` based on the pattern observed in the dataset where the `number_guess` is converted into its textual equivalent.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "Average Metric: 4.00 / 6 (66.7%): 100%|██████████| 6/6 [00:00<00:00,  7.31it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/04 18:33:55 INFO dspy.evaluate.evaluate: Average Metric: 4 / 6 (66.7%)\n",
      "2025/09/04 18:33:55 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 66.67 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 1'].\n",
      "2025/09/04 18:33:55 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67]\n",
      "2025/09/04 18:33:55 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 66.67\n",
      "2025/09/04 18:33:55 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/09/04 18:33:55 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 9 / 18 =====\n",
      "2025/09/04 18:33:55 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictor 0\n",
      "i: Given a `number_guess` input represented as a string, provide the corresponding textual `answer` by utilizing the Predict module in the program. The Predict module is designed to make predictions or generate responses based on the input `number_guess`.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "Average Metric: 4.00 / 6 (66.7%): 100%|██████████| 6/6 [00:00<00:00,  7.37it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/04 18:33:56 INFO dspy.evaluate.evaluate: Average Metric: 4 / 6 (66.7%)\n",
      "2025/09/04 18:33:56 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 66.67 with parameters ['Predictor 0: Instruction 3', 'Predictor 0: Few-Shot Set 3'].\n",
      "2025/09/04 18:33:56 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67]\n",
      "2025/09/04 18:33:56 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 66.67\n",
      "2025/09/04 18:33:56 INFO dspy.teleprompt.mipro_optimizer_v2: ========================\n",
      "\n",
      "\n",
      "2025/09/04 18:33:56 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 10 / 18 =====\n",
      "2025/09/04 18:33:56 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictor 0\n",
      "i: Given a `number_guess` input represented as a string, provide the corresponding textual `answer` by utilizing the Predict module in the program. The Predict module is designed to make predictions or generate responses based on the input `number_guess`.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "Average Metric: 4.00 / 6 (66.7%): 100%|██████████| 6/6 [00:00<00:00,  7.40it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/04 18:33:56 INFO dspy.evaluate.evaluate: Average Metric: 4 / 6 (66.7%)\n",
      "2025/09/04 18:33:56 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 66.67 with parameters ['Predictor 0: Instruction 3', 'Predictor 0: Few-Shot Set 10'].\n",
      "2025/09/04 18:33:56 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67]\n",
      "2025/09/04 18:33:56 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 66.67\n",
      "2025/09/04 18:33:56 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/09/04 18:33:56 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 11 / 18 =====\n",
      "2025/09/04 18:33:56 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictor 0\n",
      "i: Guess a number from 1 to 3\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "Average Metric: 4.00 / 6 (66.7%): 100%|██████████| 6/6 [00:00<00:00,  6.81it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/04 18:33:57 INFO dspy.evaluate.evaluate: Average Metric: 4 / 6 (66.7%)\n",
      "2025/09/04 18:33:57 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 66.67 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 0'].\n",
      "2025/09/04 18:33:57 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67]\n",
      "2025/09/04 18:33:57 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 66.67\n",
      "2025/09/04 18:33:57 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/09/04 18:33:57 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 12 / 18 =====\n",
      "2025/09/04 18:33:57 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictor 0\n",
      "i: Based on the dataset examples where a `number_guess` is converted into its corresponding `answer`, please predict the textual answer for the given `number_guess`.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "Average Metric: 4.00 / 6 (66.7%): 100%|██████████| 6/6 [00:00<00:00,  6.50it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/04 18:33:58 INFO dspy.evaluate.evaluate: Average Metric: 4 / 6 (66.7%)\n",
      "2025/09/04 18:33:58 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 66.67 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 6'].\n",
      "2025/09/04 18:33:58 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67]\n",
      "2025/09/04 18:33:58 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 66.67\n",
      "2025/09/04 18:33:58 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/09/04 18:33:58 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 13 / 18 =====\n",
      "2025/09/04 18:33:58 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictor 0\n",
      "i: Based on the dataset examples where a `number_guess` is converted into its corresponding `answer`, please predict the textual answer for the given `number_guess`.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "Average Metric: 4.00 / 6 (66.7%): 100%|██████████| 6/6 [00:01<00:00,  4.73it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/04 18:34:00 INFO dspy.evaluate.evaluate: Average Metric: 4 / 6 (66.7%)\n",
      "2025/09/04 18:34:00 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 66.67 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 8'].\n",
      "2025/09/04 18:34:00 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67]\n",
      "2025/09/04 18:34:00 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 66.67\n",
      "2025/09/04 18:34:00 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/09/04 18:34:00 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 14 / 18 =====\n",
      "2025/09/04 18:34:00 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictor 0\n",
      "i: Based on the dataset examples where a `number_guess` is converted into its corresponding `answer`, please predict the textual answer for the given `number_guess`.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "Average Metric: 4.00 / 6 (66.7%): 100%|██████████| 6/6 [00:00<00:00,  7.89it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/04 18:34:00 INFO dspy.evaluate.evaluate: Average Metric: 4 / 6 (66.7%)\n",
      "2025/09/04 18:34:00 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 66.67 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 0'].\n",
      "2025/09/04 18:34:00 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67]\n",
      "2025/09/04 18:34:00 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 66.67\n",
      "2025/09/04 18:34:00 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/09/04 18:34:00 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 15 / 18 =====\n",
      "2025/09/04 18:34:00 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictor 0\n",
      "i: Guess a number from 1 to 3\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "Average Metric: 4.00 / 6 (66.7%): 100%|██████████| 6/6 [00:00<00:00,  6.22it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/04 18:34:01 INFO dspy.evaluate.evaluate: Average Metric: 4 / 6 (66.7%)\n",
      "2025/09/04 18:34:01 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 66.67 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 7'].\n",
      "2025/09/04 18:34:01 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67]\n",
      "2025/09/04 18:34:01 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 66.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/04 18:34:01 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/09/04 18:34:01 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 16 / 18 =====\n",
      "2025/09/04 18:34:01 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictor 0\n",
      "i: Given a `number_guess` as a string input, use the language models in the pipeline to predict and generate the corresponding textual `answer` based on the pattern observed in the dataset where the `number_guess` is converted into its textual equivalent.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "Average Metric: 4.00 / 6 (66.7%): 100%|██████████| 6/6 [00:00<00:00,  6.55it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/04 18:34:02 INFO dspy.evaluate.evaluate: Average Metric: 4 / 6 (66.7%)\n",
      "2025/09/04 18:34:02 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 66.67 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 9'].\n",
      "2025/09/04 18:34:02 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67]\n",
      "2025/09/04 18:34:02 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 66.67\n",
      "2025/09/04 18:34:02 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/09/04 18:34:02 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 17 / 18 =====\n",
      "2025/09/04 18:34:02 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictor 0\n",
      "i: Guess a number from 1 to 3\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "Average Metric: 4.00 / 6 (66.7%): 100%|██████████| 6/6 [00:00<00:00,  6.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/04 18:34:03 INFO dspy.evaluate.evaluate: Average Metric: 4 / 6 (66.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/04 18:34:03 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 66.67 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 11'].\n",
      "2025/09/04 18:34:03 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67]\n",
      "2025/09/04 18:34:03 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 66.67\n",
      "2025/09/04 18:34:03 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/09/04 18:34:03 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 18 / 18 =====\n",
      "2025/09/04 18:34:03 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictor 0\n",
      "i: Given a `number_guess` as a string input, use the language models in the pipeline to predict and generate the corresponding textual `answer` based on the pattern observed in the dataset where the `number_guess` is converted into its textual equivalent.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "Average Metric: 4.00 / 6 (66.7%): 100%|██████████| 6/6 [00:01<00:00,  5.88it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/04 18:34:05 INFO dspy.evaluate.evaluate: Average Metric: 4 / 6 (66.7%)\n",
      "2025/09/04 18:34:05 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 66.67 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 0'].\n",
      "2025/09/04 18:34:05 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67]\n",
      "2025/09/04 18:34:05 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 66.67\n",
      "2025/09/04 18:34:05 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/09/04 18:34:05 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 19 / 18 =====\n",
      "2025/09/04 18:34:05 INFO dspy.teleprompt.mipro_optimizer_v2: Evaluating the following candidate program...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictor 0\n",
      "i: Based on the dataset examples where a `number_guess` is converted into its corresponding `answer`, please predict the textual answer for the given `number_guess`.\n",
      "p: Answer:\n",
      "\n",
      "\n",
      "Average Metric: 4.00 / 6 (66.7%): 100%|██████████| 6/6 [00:00<00:00,  7.20it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/04 18:34:05 INFO dspy.evaluate.evaluate: Average Metric: 4 / 6 (66.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/04 18:34:05 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 66.67 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 3'].\n",
      "2025/09/04 18:34:05 INFO dspy.teleprompt.mipro_optimizer_v2: Scores so far: [66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67, 66.67]\n",
      "2025/09/04 18:34:05 INFO dspy.teleprompt.mipro_optimizer_v2: Best score so far: 66.67\n",
      "2025/09/04 18:34:05 INFO dspy.teleprompt.mipro_optimizer_v2: =========================\n",
      "\n",
      "\n",
      "2025/09/04 18:34:05 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 66.67!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"traces\": [],\n",
      "  \"train\": [],\n",
      "  \"demos\": [],\n",
      "  \"signature\": {\n",
      "    \"instructions\": \"Guess a number from 1 to 3\",\n",
      "    \"fields\": [\n",
      "      {\n",
      "        \"prefix\": \"Number Guess:\",\n",
      "        \"description\": \"${number_guess}\"\n",
      "      },\n",
      "      {\n",
      "        \"prefix\": \"Answer:\",\n",
      "        \"description\": \"${answer}\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"lm\": null,\n",
      "  \"metadata\": {\n",
      "    \"dependency_versions\": {\n",
      "      \"python\": \"3.12\",\n",
      "      \"dspy\": \"3.0.1\",\n",
      "      \"cloudpickle\": \"3.1\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import dspy \n",
    "from common.my_settings import MySettings  \n",
    "from common.utils import md\n",
    "from common.llm_client_factory import LlmClientFactory\n",
    "from dspy_utils.dspy_helpers import md_dspy\n",
    "\n",
    "settings = MySettings().get()\n",
    "\n",
    "lm_gpt35 = dspy.LM('gpt-3.5-turbo', temperature=0.8, model_type='chat', cache=False, api_key=settings.OPENAI_API_KEY)\n",
    "lm_gpt4 = dspy.LM('gpt-4.1', temperature=0.9, model_type='chat', cache=False, api_key=settings.OPENAI_API_KEY)\n",
    "dspy.configure(lm=lm_gpt4)\n",
    "\n",
    "# Create domain classes\n",
    "from typing import Literal\n",
    "    \n",
    "class NumberPicker(dspy.Signature):\n",
    "    \"\"\"Guess a number from 1 to 10\"\"\"\n",
    "    number_guess: str = dspy.InputField()\n",
    "    answer: Literal[\"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\", \"ten\"] = dspy.OutputField()\n",
    "\n",
    "numberPickerPredict = dspy.Predict(NumberPicker)\n",
    "numberPickerPredict(number_guess=\"even\")\n",
    "\n",
    "trainset = [\n",
    "    dspy.Example(number_guess=\"1\", answer=\"one\").with_inputs(\"number_guess\"),\n",
    "    dspy.Example(number_guess=\"2\", answer=\"two\").with_inputs(\"number_guess\"),\n",
    "    dspy.Example(number_guess=\"Four\", answer=\"four\").with_inputs(\"number_guess\"),\n",
    "    dspy.Example(number_guess=\"Five\", answer=\"five\").with_inputs(\"number_guess\"),\n",
    "    dspy.Example(number_guess=\"The number: 3\", answer=\"three\").with_inputs(\"number_guess\"),\n",
    "    dspy.Example(number_guess=\"6\", answer=\"six\").with_inputs(\"number_guess\"),\n",
    "    dspy.Example(number_guess=\"7\", answer=\"seven\").with_inputs(\"number_guess\"),\n",
    "    dspy.Example(number_guess=\"The number: 8\", answer=\"eight\").with_inputs(\"number_guess\"),\n",
    "    dspy.Example(number_guess=\"The number: 10\", answer=\"ten\").with_inputs(\"number_guess\"),\n",
    "]\n",
    "\n",
    "def validate_match(expected, actual, trace=None) -> bool:\n",
    "    # print()\n",
    "    # md(\"**expected**: \", expected)\n",
    "    # print(\"**actual**: \", actual)\n",
    "    # md(\"**Is match**: \", actual.answer == \"two\")\n",
    "    # print()\n",
    "    return (actual.answer == \"three\")\n",
    "\n",
    "from dspy.teleprompt import *\n",
    "\n",
    "tp = dspy.MIPROv2(metric=validate_match, auto=\"medium\", prompt_model=lm_gpt35, task_model=lm_gpt4, verbose=True)\n",
    "optimized_matcher = tp.compile(numberPickerPredict, trainset=trainset, requires_permission_to_run=False)\n",
    "optimized_matcher.save(\"./saved_files/test.json\")\n",
    "\n",
    "import json\n",
    "\n",
    "with open(\"./saved_files/test.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(json.dumps(data, indent=2))\n",
    "\n",
    "print(\"Done.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

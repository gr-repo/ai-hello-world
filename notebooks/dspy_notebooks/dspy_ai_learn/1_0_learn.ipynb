{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "633589ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting keys from environment variables\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Hello! How can I assist you today?']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import dspy \n",
    "from common.my_settings import MySettings  \n",
    "from common.utils import md\n",
    "from common.llm_client_factory import LlmClientFactory\n",
    "from dspy_utils.dspy_helpers import md_dspy\n",
    "\n",
    "settings = MySettings().get()\n",
    "\n",
    "lm_gpt35 = dspy.LM('gpt-3.5-turbo', temperature=0.8, model_type='chat', cache=False, api_key=settings.OPENAI_API_KEY)\n",
    "lm_gpt4omin = dspy.LM('gpt-4o-mini', temperature=0.9, model_type='chat', cache=False, api_key=settings.OPENAI_API_KEY)\n",
    "dspy.configure(lm=lm_gpt4omin)\n",
    "\n",
    "lm = lm_gpt4omin\n",
    "lm('hello there')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7b012a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I don’t have real-time data access to check the current weather. You can use a weather website or app for the latest updates on the weather in your area. If you let me know your location, I can suggest how to find that information!']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_gpt4omin('Hows the weather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00323d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'prompt': 'hello there',\n",
       "  'messages': None,\n",
       "  'kwargs': {},\n",
       "  'response': ModelResponse(id='chatcmpl-CC9lWbC3WhS9UlxSIstQ37mZJYeoR', created=1757013510, model='gpt-4o-mini-2024-07-18', object='chat.completion', system_fingerprint='fp_560af6e559', choices=[Choices(finish_reason='stop', index=0, message=Message(content='Hello! How can I assist you today?', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=9, prompt_tokens=9, total_tokens=18, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default', cache_hit=None),\n",
       "  'outputs': ['Hello! How can I assist you today?'],\n",
       "  'usage': {'completion_tokens': 9,\n",
       "   'prompt_tokens': 9,\n",
       "   'total_tokens': 18,\n",
       "   'completion_tokens_details': CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None),\n",
       "   'prompt_tokens_details': PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)},\n",
       "  'cost': 6.75e-06,\n",
       "  'timestamp': '2025-09-04T21:18:30.941842',\n",
       "  'uuid': '84409f93-a8b4-402f-94b7-85a1ce5d76fa',\n",
       "  'model': 'gpt-4o-mini',\n",
       "  'response_model': 'gpt-4o-mini-2024-07-18',\n",
       "  'model_type': 'chat'},\n",
       " {'prompt': 'Hows the weather',\n",
       "  'messages': None,\n",
       "  'kwargs': {},\n",
       "  'response': ModelResponse(id='chatcmpl-CC9lbTtsXcoCxdMv8lwZUtfuNzC1S', created=1757013515, model='gpt-4o-mini-2024-07-18', object='chat.completion', system_fingerprint='fp_8bda4d3a2c', choices=[Choices(finish_reason='stop', index=0, message=Message(content='I don’t have real-time data access to check the current weather. You can use a weather website or app for the latest updates on the weather in your area. If you let me know your location, I can suggest how to find that information!', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=50, prompt_tokens=11, total_tokens=61, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default', cache_hit=None),\n",
       "  'outputs': ['I don’t have real-time data access to check the current weather. You can use a weather website or app for the latest updates on the weather in your area. If you let me know your location, I can suggest how to find that information!'],\n",
       "  'usage': {'completion_tokens': 50,\n",
       "   'prompt_tokens': 11,\n",
       "   'total_tokens': 61,\n",
       "   'completion_tokens_details': CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None),\n",
       "   'prompt_tokens_details': PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)},\n",
       "  'cost': 3.165e-05,\n",
       "  'timestamp': '2025-09-04T21:18:36.713883',\n",
       "  'uuid': '00e10bee-f503-41d1-8908-685b87c59994',\n",
       "  'model': 'gpt-4o-mini',\n",
       "  'response_model': 'gpt-4o-mini-2024-07-18',\n",
       "  'model_type': 'chat'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_gpt4omin.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ac54907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-04 21:22:01.352007\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4829e625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['prompt', 'messages', 'kwargs', 'response', 'outputs', 'usage', 'cost', 'timestamp', 'uuid', 'model', 'response_model', 'model_type'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lm.history)\n",
    "lm.history[-1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed95b2d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxicity = dspy.Predict(\n",
    "    dspy.Signature(\n",
    "        \"comment -> toxic: bool\", \n",
    "        instructions=\"Mark as 'toxic' if the comment includes insults, harrasment or sarcastic comments\"\n",
    "    )\n",
    ")\n",
    "\n",
    "toxicity(comment=\"You are awesome\").toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aac4f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Savor a flavorful Bobotie, a spiced minced meat dish topped with egg custard, served with fragrant rice and chutney."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "choose_meal = dspy.Predict(\n",
    "    dspy.Signature(\n",
    "    \"meal_suggestion -> description\",\n",
    "    instructions=\"Given a meal suggestion come up with a meal and desribe it in 20 words, make it sound enticing without going overboard\"\n",
    "))\n",
    "\n",
    "md(choose_meal(meal_suggestion=\"South African\").description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9074efe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Today is rainy and gloomy\"\n",
    "\n",
    "classify = dspy.Predict(\"sentence -> sentiment: str\") # change type: int, float, str, bool\n",
    "classify(sentence=sentence).sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d06af824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Arrr, let’s venture to a tavern tonight and lend an ear to a crew of musicians!'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argh = \"Let's go to a bar tonight and listen to a band\"\n",
    "pirate_speak = dspy.Predict(\"normal_speak -> pirate_speak\")\n",
    "pirate_speak(normal_speak=argh).pirate_speak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c0c6421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Prediction(  \n",
       "    answer='Plant leaves are primarily green due to the presence of chlorophyll, which is essential for photosynthesis. However, leaves can also be other colors, such as red, purple, yellow, or even variegated, depending on the plant species and environmental factors like sunlight and soil nutrients.'  \n",
       ")"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"What colour are plant leaves?\"\n",
    "reason_question = dspy.Predict(\"question -> answer\")\n",
    "md(reason_question(question=question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69a2cb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    sentiment='sadness'\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Literal\n",
    "\n",
    "class Emotion(dspy.Signature):\n",
    "    \"\"\"Classify emotion\"\"\"\n",
    "    sentence: str = dspy.InputField()\n",
    "    sentiment: Literal[\"sadness\", \"joy\", \"love\", \"fear\", \"surprised\"]  = dspy.OutputField()\n",
    "\n",
    "classify = dspy.Predict(Emotion)\n",
    "classify(sentence=\"rainy day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ed06b6",
   "metadata": {},
   "source": [
    "https://dspy.ai/learn/programming/signatures/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "289ffb7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning='The text claims that Lee scored 3 goals for Colchester United, but the context states that he scored twice for them. Therefore, the statement in the text is incorrect based on the provided context.',\n",
       "    faithfulness=0.0,\n",
       "    evidence={'goals_scored': [\"Lee scored twice for the U's\", 'unable to save them from relegation']},\n",
       "    counter_argument={'text_inaccuracy': {'claim': 'Lee scored 3 goals for Colchester United', 'correction': 'Lee actually scored 2 goals for Colchester United'}}\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CheckCitationOfFaithfulness(dspy.Signature):\n",
    "    \"\"\"Verify that the text is based on the provided context.\"\"\"\n",
    "    context: str = dspy.InputField(desc=\"Facts here are assumed to be true\")\n",
    "    text: str = dspy.InputField()\n",
    "    faithfulness: float = dspy.OutputField()\n",
    "    evidence: dict[str, list[str]] = dspy.OutputField(desc=\"Supporting evidence for claims\")\n",
    "    counter_argument: dict[str, dict[str, str]] = dspy.OutputField(desc=\"Give a counter argument to this\")\n",
    "\n",
    "context = \"\"\"\n",
    "The 21-year-old made seven appearances for the Hammers and netted his only \n",
    "goal for them in a Europa League qualification round match against Andorran side \n",
    "FC Lustrains last season. Lee had two loan spells in League One last term, \n",
    "with Blackpool and then Colchester United. He scored twice for the U's but \n",
    "was unable to save them from relegation. \n",
    "The length of Lee's contract with the promoted Tykes has not been revealed. \n",
    "Find all the latest football transfers on our dedicated page.\n",
    "\"\"\"\n",
    "text = \"Lee scored 3 goals for the Colchester United\"\n",
    "\n",
    "faithfulness = dspy.ChainOfThought(CheckCitationOfFaithfulness)\n",
    "faithfulness(context=context, text=text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24e7b8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "LlmClientFactory.get_dspy_lm_chat_connecting_to_internal_databricks_model() missing 1 required positional argument: 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m factory = LlmClientFactory(settings)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m db = \u001b[43mfactory\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_dspy_lm_chat_connecting_to_internal_databricks_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: LlmClientFactory.get_dspy_lm_chat_connecting_to_internal_databricks_model() missing 1 required positional argument: 'model'"
     ]
    }
   ],
   "source": [
    "# factory = LlmClientFactory(settings)\n",
    "# db = factory.get_dspy_lm_chat_connecting_to_internal_databricks_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d27490be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    answer='Labrador Retriever'\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PictureSignature(dspy.Signature):\n",
    "    \"\"\"Output the dog breed of the picture\"\"\"\n",
    "    image_1: dspy.Image = dspy.InputField(desc=\"An image of a dog\")\n",
    "    answer: str = dspy.OutputField(desc=\"The dog breed of the dog in the picture\")\n",
    "\n",
    "picture = dspy.Predict(PictureSignature)\n",
    "picture(image_1=dspy.Image.from_url(\"https://fastly.picsum.photos/id/237/200/300.jpg?hmac=TmmQSbShHz9CdQm0NkEjx1Dyh_Y984R9LpNrpvH2D_U\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
